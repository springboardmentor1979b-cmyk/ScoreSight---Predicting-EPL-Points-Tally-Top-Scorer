âš½ Football Analytics System
Match Outcome & Player Performance Prediction using Machine Learning

This project implements a complete end-to-end football analytics pipeline, starting from raw match data and ending with a production-ready Streamlit application.

It combines:

Classification â†’ Predicting match outcome (Win / Draw / Loss)

Regression â†’ Predicting individual player performance (Score â†’ Star Rating)

ğŸ“Œ Project Overview

Dataset: Football match and player statistics

Models Used:

Gradient Boosting Classifier (Match Outcome)

Random Forest Regressor (Player Performance)

Frontend: Streamlit

Focus Areas:

Data integrity

Feature engineering

Leakage prevention

Interpretability

Deployment-ready inference

ğŸ“ Project Structure
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ 2020-09-24.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ football_ml_pipeline.ipynb
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ top5_gradient_boosting_classifier.pkl
â”‚   â”œâ”€â”€ top5_random_forest_regressor.pkl
â”‚   â”œâ”€â”€ top5_classification_imputer.pkl
â”‚   â””â”€â”€ top5_regression_imputer.pkl
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ app_layout.png
â”‚   â”œâ”€â”€ match_outcome_prediction.png
â”‚   â””â”€â”€ player_performance_prediction.png
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ§  Machine Learning Workflow
(20-Step Training & Evaluation Pipeline)

This section documents the complete workflow used to train, optimize, and validate the models.

1ï¸âƒ£ Setup & Data Loading

Imported core libraries: pandas, matplotlib, scikit-learn

Loaded the raw dataset: 2020-09-24.csv

2ï¸âƒ£ Initial Inspection

Dataset inspection using:

.shape

.info()

.describe()

Identified missing values and datatype inconsistencies

3ï¸âƒ£ Role-Based Feature Categorization

Grouped columns by player role:

Goalkeeper

Defender

Midfielder

Attacker

Enabled role-aware data processing

4ï¸âƒ£ Logic-Based Data Cleaning

Removed irrelevant identifiers:

Player Name

Jersey Number

Resolved ambiguous 0 values:

Treated as valid or missing based on player role

5ï¸âƒ£ Exploratory Data Analysis (EDA)

Visualizations:

Goal distributions

Shots vs Goals scatter plots

Match statistics bar charts

Identified skewness and correlations

6ï¸âƒ£ Feature Cleaning

Converted percentage-based features (e.g., Tackle success %) from strings to numeric values

7ï¸âƒ£ Feature Scaling

Applied:

MinMaxScaler

StandardScaler

Compared distributions before and after scaling

8ï¸âƒ£ Target Engineering
ğŸ”¹ MatchOutcome (Classification)

Derived from match results

Classes:

Win

Draw

Loss

ğŸ”¹ PerformanceScore (Regression)

Engineered using normalized player statistics:

Assists

Tackles

Clearances

Saves

Clean Sheets

9ï¸âƒ£ Role-Aware Imputation Strategy

Implemented custom logic:

Non-role features set to 0

Role-specific missing values filled using role medians

ğŸ”Ÿ Data Preparation

Separated features (X) and targets (y)

One-hot encoded categorical features

Label encoded classification target where required

1ï¸âƒ£1ï¸âƒ£ Leakage Prevention

Removed features used in target construction from model inputs

Ensured no information leakage

1ï¸âƒ£2ï¸âƒ£ Trainâ€“Test Split

Split data into:

80% training

20% testing

Performed separately for both tasks

1ï¸âƒ£3ï¸âƒ£ Final Imputation

Applied SimpleImputer(strategy="median")

Ensured consistent preprocessing

1ï¸âƒ£4ï¸âƒ£ Baseline Models

Regression: Linear Regression

Classification: Logistic Regression

1ï¸âƒ£5ï¸âƒ£ Baseline Evaluation

Regression metrics:

MAE

RMSE

RÂ²

Classification metrics:

Accuracy

Precision

Recall

F1-score

1ï¸âƒ£6ï¸âƒ£ Advanced Models

Regression: Random Forest Regressor

Classification: Gradient Boosting Classifier

1ï¸âƒ£7ï¸âƒ£ Hyperparameter Tuning

Random Forest â†’ GridSearchCV

Gradient Boosting â†’ RandomizedSearchCV

1ï¸âƒ£8ï¸âƒ£ Feature Selection (Top-5)

Selected the 5 most important features for each task

Retrained optimized models using only these features

Improved interpretability and deployment efficiency

1ï¸âƒ£9ï¸âƒ£ Model Serialization

Saved models and imputers using joblib

Produced .pkl files for deployment

2ï¸âƒ£0ï¸âƒ£ Inference Testing

Reloaded saved models

Tested on manually constructed edge cases

Verified prediction consistency

ğŸš€ Streamlit Application â€” Inference Pipeline

The Streamlit app provides a clean frontend interface for real-time predictions using pre-trained models.

ğŸ”¹ Application Layout

Overall structure of the Streamlit app

ğŸ“¸ Screenshot Placeholder â€” App Layout

[ app_layout.png ]

ğŸ”¹ Match Outcome Prediction
Input Features

Shots (standardized)

Passes

Big chances created

Yellow cards

Red cards

Prediction Flow

User inputs collected

Features aligned with training schema

Missing values handled via trained imputer

Gradient Boosting model predicts outcome

Output

Win â†’ Green banner

Draw â†’ Blue banner

Loss â†’ Red banner

ğŸ“¸ Screenshots

![Application interface](screenshots/match_outcome_prediction_page.png)
![Match Outcome Prediction](screenshots/match_outcome_prediction.png)
![Player Performance Prediction](screenshots/player_performance_prediction.png)


Input Features

Assists

Tackles

Clearances

Saves

Clean sheets

Prediction Flow

User inputs collected

Feature alignment ensures schema consistency

Random Forest model predicts raw score

Score normalized relative to observed max (2.55)

Output

Star rating (â­ to â­â­â­â­â­)

Qualitative label (Poor â†’ Elite)

Progress bar visualization

ğŸ“¸ Screenshot Placeholder â€” Player Performance Prediction

[ player_performance_prediction.png ]

ğŸ› ï¸ How to Run the Application
pip install -r requirements.txt
streamlit run app.py

ğŸ“Œ Key Highlights

End-to-end ML pipeline

Strong data integrity and leakage prevention

Lightweight deployment models

Interpretable predictions

Production-grade Streamlit UI

ğŸ‘¤ Author

Shivanshu